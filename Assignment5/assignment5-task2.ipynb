{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1808590,"sourceType":"datasetVersion","datasetId":989445}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertModel, BertForSequenceClassification\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:33:32.403054Z","iopub.execute_input":"2025-04-19T11:33:32.403312Z","iopub.status.idle":"2025-04-19T11:33:57.068153Z","shell.execute_reply.started":"2025-04-19T11:33:32.403289Z","shell.execute_reply":"2025-04-19T11:33:57.067529Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 11:33:46.129466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745062426.324321      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745062426.390306      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:33:57.069273Z","iopub.execute_input":"2025-04-19T11:33:57.070021Z","iopub.status.idle":"2025-04-19T11:33:57.075604Z","shell.execute_reply.started":"2025-04-19T11:33:57.069999Z","shell.execute_reply":"2025-04-19T11:33:57.074939Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Load train dataset\ntrain_df = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/train.csv\", encoding='ISO-8859-1')\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:06.961103Z","iopub.execute_input":"2025-04-19T11:34:06.961388Z","iopub.status.idle":"2025-04-19T11:34:07.141084Z","shell.execute_reply.started":"2025-04-19T11:34:06.961365Z","shell.execute_reply":"2025-04-19T11:34:07.140369Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment Time of Tweet Age of User  \\\n0  I`d have responded, if I were going   neutral       morning        0-20   \n1                             Sooo SAD  negative          noon       21-30   \n2                          bullying me  negative         night       31-45   \n3                       leave me alone  negative       morning       46-60   \n4                        Sons of ****,  negative          noon       60-70   \n\n       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n0  Afghanistan          38928346         652860.0               60  \n1      Albania           2877797          27400.0              105  \n2      Algeria          43851044        2381740.0               18  \n3      Andorra             77265            470.0              164  \n4       Angola          32866272        1246700.0               26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Load test dataset\ntest_df = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/test.csv\", encoding='ISO-8859-1')\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:11.279371Z","iopub.execute_input":"2025-04-19T11:34:11.280089Z","iopub.status.idle":"2025-04-19T11:34:11.312426Z","shell.execute_reply.started":"2025-04-19T11:34:11.280064Z","shell.execute_reply":"2025-04-19T11:34:11.311655Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       textID                                               text sentiment  \\\n0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n3  01082688c6                                        happy bday!  positive   \n4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n\n  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n0       morning        0-20  Afghanistan        38928346.0         652860.0   \n1          noon       21-30      Albania         2877797.0          27400.0   \n2         night       31-45      Algeria        43851044.0        2381740.0   \n3       morning       46-60      Andorra           77265.0            470.0   \n4          noon       60-70       Angola        32866272.0        1246700.0   \n\n   Density (P/Km²)  \n0             60.0  \n1            105.0  \n2             18.0  \n3            164.0  \n4             26.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346.0</td>\n      <td>652860.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>Shanghai is also really exciting (precisely -...</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797.0</td>\n      <td>27400.0</td>\n      <td>105.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>Recession hit Veronique Branquinho, she has to...</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044.0</td>\n      <td>2381740.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n      <td>positive</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265.0</td>\n      <td>470.0</td>\n      <td>164.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272.0</td>\n      <td>1246700.0</td>\n      <td>26.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Preprocess labels\nlabel_map = {'negative': 0, 'neutral': 1, 'positive': 2}\ntrain_df = train_df[train_df['sentiment'].isin(label_map.keys())]  # Filter valid sentiments\ntrain_df['label'] = train_df['sentiment'].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:16.482381Z","iopub.execute_input":"2025-04-19T11:34:16.483092Z","iopub.status.idle":"2025-04-19T11:34:16.500204Z","shell.execute_reply.started":"2025-04-19T11:34:16.483070Z","shell.execute_reply":"2025-04-19T11:34:16.499376Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:20.223197Z","iopub.execute_input":"2025-04-19T11:34:20.223912Z","iopub.status.idle":"2025-04-19T11:34:20.235034Z","shell.execute_reply.started":"2025-04-19T11:34:20.223880Z","shell.execute_reply":"2025-04-19T11:34:20.234130Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment Time of Tweet Age of User  \\\n0  I`d have responded, if I were going   neutral       morning        0-20   \n1                             Sooo SAD  negative          noon       21-30   \n2                          bullying me  negative         night       31-45   \n3                       leave me alone  negative       morning       46-60   \n4                        Sons of ****,  negative          noon       60-70   \n\n       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  label  \n0  Afghanistan          38928346         652860.0               60      1  \n1      Albania           2877797          27400.0              105      0  \n2      Algeria          43851044        2381740.0               18      0  \n3      Andorra             77265            470.0              164      0  \n4       Angola          32866272        1246700.0               26      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Train-validation split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_df['text'].tolist(), train_df['label'].tolist(), test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T11:34:22.360471Z","iopub.execute_input":"2025-04-19T11:34:22.360736Z","iopub.status.idle":"2025-04-19T11:34:22.375235Z","shell.execute_reply.started":"2025-04-19T11:34:22.360716Z","shell.execute_reply":"2025-04-19T11:34:22.374395Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Ensure text data is string and drop missing values\nfiltered = [(str(text), label) for text, label in zip(train_texts, train_labels) if pd.notnull(text)]\ntrain_texts, train_labels = zip(*filtered)\ntrain_texts = list(train_texts)\ntrain_labels = list(train_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:24.513359Z","iopub.execute_input":"2025-04-19T11:34:24.513637Z","iopub.status.idle":"2025-04-19T11:34:24.535498Z","shell.execute_reply.started":"2025-04-19T11:34:24.513615Z","shell.execute_reply":"2025-04-19T11:34:24.534849Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# val_texts = [str(text) for text in val_texts if pd.notnull(text)]\nfiltered = [(str(text), label) for text, label in zip(val_texts, val_labels) if pd.notnull(text)]\nval_texts, val_labels = zip(*filtered)\nval_texts = list(val_texts)\nval_labels = list(val_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:24.881235Z","iopub.execute_input":"2025-04-19T11:34:24.881511Z","iopub.status.idle":"2025-04-19T11:34:24.892355Z","shell.execute_reply.started":"2025-04-19T11:34:24.881492Z","shell.execute_reply":"2025-04-19T11:34:24.891567Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"len(train_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:26.440263Z","iopub.execute_input":"2025-04-19T11:34:26.440780Z","iopub.status.idle":"2025-04-19T11:34:26.445248Z","shell.execute_reply.started":"2025-04-19T11:34:26.440758Z","shell.execute_reply":"2025-04-19T11:34:26.444698Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"21983"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"len(train_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:26.784318Z","iopub.execute_input":"2025-04-19T11:34:26.784877Z","iopub.status.idle":"2025-04-19T11:34:26.789426Z","shell.execute_reply.started":"2025-04-19T11:34:26.784849Z","shell.execute_reply":"2025-04-19T11:34:26.788885Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"21983"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Preprocess labels\nlabel_map = {'negative': 0, 'neutral': 1, 'positive': 2}\ntest_df = test_df[test_df['sentiment'].isin(label_map.keys())]  # Filter valid sentiments\ntest_df['label'] = test_df['sentiment'].map(label_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:49.687992Z","iopub.execute_input":"2025-04-19T11:34:49.688517Z","iopub.status.idle":"2025-04-19T11:34:49.697649Z","shell.execute_reply.started":"2025-04-19T11:34:49.688494Z","shell.execute_reply":"2025-04-19T11:34:49.696857Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:34:51.289668Z","iopub.execute_input":"2025-04-19T11:34:51.289965Z","iopub.status.idle":"2025-04-19T11:34:51.301029Z","shell.execute_reply.started":"2025-04-19T11:34:51.289945Z","shell.execute_reply":"2025-04-19T11:34:51.300315Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       textID                                               text sentiment  \\\n0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n3  01082688c6                                        happy bday!  positive   \n4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n\n  Time of Tweet Age of User      Country  Population -2020  Land Area (Km²)  \\\n0       morning        0-20  Afghanistan        38928346.0         652860.0   \n1          noon       21-30      Albania         2877797.0          27400.0   \n2         night       31-45      Algeria        43851044.0        2381740.0   \n3       morning       46-60      Andorra           77265.0            470.0   \n4          noon       60-70       Angola        32866272.0        1246700.0   \n\n   Density (P/Km²)  label  \n0             60.0      1  \n1            105.0      2  \n2             18.0      0  \n3            164.0      2  \n4             26.0      2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346.0</td>\n      <td>652860.0</td>\n      <td>60.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>Shanghai is also really exciting (precisely -...</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797.0</td>\n      <td>27400.0</td>\n      <td>105.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>Recession hit Veronique Branquinho, she has to...</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044.0</td>\n      <td>2381740.0</td>\n      <td>18.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n      <td>positive</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265.0</td>\n      <td>470.0</td>\n      <td>164.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272.0</td>\n      <td>1246700.0</td>\n      <td>26.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"test_df = test_df[pd.notnull(test_df['text'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:36:28.398042Z","iopub.execute_input":"2025-04-19T11:36:28.398684Z","iopub.status.idle":"2025-04-19T11:36:28.403103Z","shell.execute_reply.started":"2025-04-19T11:36:28.398664Z","shell.execute_reply":"2025-04-19T11:36:28.402490Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Extract text and sentiment \ntest_texts = list(test_df['text'])\ntest_labels = list(test_df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:36:29.689694Z","iopub.execute_input":"2025-04-19T11:36:29.690264Z","iopub.status.idle":"2025-04-19T11:36:29.694640Z","shell.execute_reply.started":"2025-04-19T11:36:29.690239Z","shell.execute_reply":"2025-04-19T11:36:29.693865Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"len(test_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:36:37.575021Z","iopub.execute_input":"2025-04-19T11:36:37.575289Z","iopub.status.idle":"2025-04-19T11:36:37.580060Z","shell.execute_reply.started":"2025-04-19T11:36:37.575272Z","shell.execute_reply":"2025-04-19T11:36:37.579500Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"3534"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"len(test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:36:48.152699Z","iopub.execute_input":"2025-04-19T11:36:48.153290Z","iopub.status.idle":"2025-04-19T11:36:48.157734Z","shell.execute_reply.started":"2025-04-19T11:36:48.153265Z","shell.execute_reply":"2025-04-19T11:36:48.156841Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"3534"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:37:11.878114Z","iopub.execute_input":"2025-04-19T11:37:11.878686Z","iopub.status.idle":"2025-04-19T11:37:13.195029Z","shell.execute_reply.started":"2025-04-19T11:37:11.878667Z","shell.execute_reply":"2025-04-19T11:37:13.194216Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9664a59931db4aa8800f107729fff5f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db94b260da6440f39360abec412031cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58607384f77b42c79bbf8a21d2c2f780"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f09cf282544108b46683284d9b074e"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Tokenize\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:37:17.378174Z","iopub.execute_input":"2025-04-19T11:37:17.378420Z","iopub.status.idle":"2025-04-19T11:37:19.415430Z","shell.execute_reply.started":"2025-04-19T11:37:17.378404Z","shell.execute_reply":"2025-04-19T11:37:19.414665Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels  # keep as list\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:37:19.416548Z","iopub.execute_input":"2025-04-19T11:37:19.416847Z","iopub.status.idle":"2025-04-19T11:37:19.421900Z","shell.execute_reply.started":"2025-04-19T11:37:19.416804Z","shell.execute_reply":"2025-04-19T11:37:19.421204Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"train_dataset = SentimentDataset(train_encodings, train_labels)\nval_dataset = SentimentDataset(val_encodings, val_labels)\ntest_dataset = SentimentDataset(test_encodings, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:37:20.387510Z","iopub.execute_input":"2025-04-19T11:37:20.387805Z","iopub.status.idle":"2025-04-19T11:37:20.391518Z","shell.execute_reply.started":"2025-04-19T11:37:20.387784Z","shell.execute_reply":"2025-04-19T11:37:20.390886Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Training data on pretrained Bert-based model","metadata":{}},{"cell_type":"code","source":"# Load pre-trained model\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:37:56.563916Z","iopub.execute_input":"2025-04-19T11:37:56.564553Z","iopub.status.idle":"2025-04-19T11:37:59.071402Z","shell.execute_reply.started":"2025-04-19T11:37:56.564530Z","shell.execute_reply":"2025-04-19T11:37:59.070670Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf42b045b0848edb2d24f874fd9843e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:38:07.815661Z","iopub.execute_input":"2025-04-19T11:38:07.816527Z","iopub.status.idle":"2025-04-19T11:38:07.820688Z","shell.execute_reply.started":"2025-04-19T11:38:07.816492Z","shell.execute_reply":"2025-04-19T11:38:07.820016Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def train(model, train_dataset, val_dataset, epochs=3, batch_size=16):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        loop = tqdm(train_loader, leave=True)\n\n        for batch in loop:\n            # ✅ Now this works, because each batch is a dict with tensors\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(**batch)\n            loss = outputs.loss\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            total_loss += loss.item()\n            loop.set_description(f\"Epoch {epoch + 1}\")\n            loop.set_postfix(loss=loss.item())\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"\\nEpoch {epoch + 1} complete. Avg Loss = {avg_loss:.4f}\")\n\n        evaluate(model, val_loader)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:38:13.383352Z","iopub.execute_input":"2025-04-19T11:38:13.384128Z","iopub.status.idle":"2025-04-19T11:38:13.392093Z","shell.execute_reply.started":"2025-04-19T11:38:13.384097Z","shell.execute_reply":"2025-04-19T11:38:13.391136Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Evaluation\ndef evaluate(model, val_loader):\n    model.eval()\n    preds, true_labels = [], []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n            logits = outputs.logits\n            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())\n            true_labels.extend(batch['labels'].cpu().numpy())\n\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(true_labels, preds, target_names=label_map.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:38:15.730237Z","iopub.execute_input":"2025-04-19T11:38:15.730893Z","iopub.status.idle":"2025-04-19T11:38:15.738585Z","shell.execute_reply.started":"2025-04-19T11:38:15.730861Z","shell.execute_reply":"2025-04-19T11:38:15.737685Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Run training\nmodel = train(model, train_dataset, val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:38:21.552219Z","iopub.execute_input":"2025-04-19T11:38:21.552464Z","iopub.status.idle":"2025-04-19T11:51:27.905254Z","shell.execute_reply.started":"2025-04-19T11:38:21.552447Z","shell.execute_reply":"2025-04-19T11:51:27.904486Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1374/1374 [04:10<00:00,  5.48it/s, loss=0.464]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 complete. Avg Loss = 0.6009\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.86      0.65      0.74      1562\n     neutral       0.69      0.83      0.75      2230\n    positive       0.83      0.79      0.81      1705\n\n    accuracy                           0.77      5497\n   macro avg       0.79      0.76      0.77      5497\nweighted avg       0.78      0.77      0.77      5497\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1374/1374 [04:10<00:00,  5.49it/s, loss=0.534] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 complete. Avg Loss = 0.4266\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.80      0.80      0.80      1562\n     neutral       0.78      0.75      0.76      2230\n    positive       0.81      0.85      0.83      1705\n\n    accuracy                           0.80      5497\n   macro avg       0.80      0.80      0.80      5497\nweighted avg       0.79      0.80      0.79      5497\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1374/1374 [04:10<00:00,  5.49it/s, loss=0.132] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 complete. Avg Loss = 0.2934\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.80      0.76      0.78      1562\n     neutral       0.72      0.79      0.75      2230\n    positive       0.84      0.78      0.81      1705\n\n    accuracy                           0.78      5497\n   macro avg       0.79      0.78      0.78      5497\nweighted avg       0.78      0.78      0.78      5497\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Results on validation data\n\nval_loader = DataLoader(val_dataset, batch_size=16)\nevaluate(model, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:27.906889Z","iopub.execute_input":"2025-04-19T11:51:27.907146Z","iopub.status.idle":"2025-04-19T11:51:39.666085Z","shell.execute_reply.started":"2025-04-19T11:51:27.907128Z","shell.execute_reply":"2025-04-19T11:51:39.665205Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.80      0.76      0.78      1562\n     neutral       0.72      0.79      0.75      2230\n    positive       0.84      0.78      0.81      1705\n\n    accuracy                           0.78      5497\n   macro avg       0.79      0.78      0.78      5497\nweighted avg       0.78      0.78      0.78      5497\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Results on test data\n\ntest_loader = DataLoader(test_dataset, batch_size=16)\nevaluate(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:39.667057Z","iopub.execute_input":"2025-04-19T11:51:39.667322Z","iopub.status.idle":"2025-04-19T11:51:47.284291Z","shell.execute_reply.started":"2025-04-19T11:51:39.667299Z","shell.execute_reply":"2025-04-19T11:51:47.283633Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.78      0.77      0.78      1001\n     neutral       0.72      0.78      0.75      1430\n    positive       0.86      0.78      0.82      1103\n\n    accuracy                           0.78      3534\n   macro avg       0.79      0.78      0.78      3534\nweighted avg       0.78      0.78      0.78      3534\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/bert_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:04:15.354212Z","iopub.execute_input":"2025-04-19T12:04:15.354508Z","iopub.status.idle":"2025-04-19T12:04:16.005715Z","shell.execute_reply.started":"2025-04-19T12:04:15.354483Z","shell.execute_reply":"2025-04-19T12:04:16.005147Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fine-tuning the pretrained Bert model and training it on dataset","metadata":{}},{"cell_type":"code","source":"# Fine-tuned model after adding extra layers to the original classification model\n\nclass CustomBERTClassifier(nn.Module):\n    def __init__(self, dropout=0.3, hidden_size=768, num_labels=3):\n        super(CustomBERTClassifier, self).__init__()\n\n        # Start with the original classification model\n        self.bert_fc = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n\n        # Add extra custom layers after BERT's classification output\n        self.classifier = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(num_labels, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, num_labels)\n        )\n\n    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n        outputs = self.bert_fc(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            labels=labels\n        )\n\n        # Get logits from BERT\n        logits = outputs.logits  # shape: (batch_size, num_labels)\n\n        # Pass through custom classifier head\n        logits = self.classifier(logits)\n\n        # Compute loss if labels provided\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits, labels)\n\n        return {'loss': loss, 'logits': logits}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.285882Z","iopub.execute_input":"2025-04-19T11:51:47.286117Z","iopub.status.idle":"2025-04-19T11:51:47.292252Z","shell.execute_reply.started":"2025-04-19T11:51:47.286099Z","shell.execute_reply":"2025-04-19T11:51:47.291534Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"model_tuned = CustomBERTClassifier()\nmodel_tuned.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.292963Z","iopub.execute_input":"2025-04-19T11:51:47.293188Z","iopub.status.idle":"2025-04-19T11:51:47.817162Z","shell.execute_reply.started":"2025-04-19T11:51:47.293171Z","shell.execute_reply":"2025-04-19T11:51:47.816531Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"CustomBERTClassifier(\n  (bert_fc): BertForSequenceClassification(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSdpaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (classifier): Linear(in_features=768, out_features=3, bias=True)\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.3, inplace=False)\n    (1): Linear(in_features=3, out_features=768, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.3, inplace=False)\n    (4): Linear(in_features=768, out_features=3, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.817851Z","iopub.execute_input":"2025-04-19T11:51:47.818063Z","iopub.status.idle":"2025-04-19T11:51:47.823673Z","shell.execute_reply.started":"2025-04-19T11:51:47.818047Z","shell.execute_reply":"2025-04-19T11:51:47.823046Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def train(model, train_dataset, val_dataset, epochs=3, batch_size=16):\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        loop = tqdm(train_loader, leave=True)\n\n        for batch in loop:\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            outputs = model(**batch)\n            loss = outputs['loss']  # ✅ Access loss from dict\n\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            total_loss += loss.item()\n            loop.set_description(f\"Epoch {epoch + 1}\")\n            loop.set_postfix(loss=loss.item())\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"\\nEpoch {epoch + 1} complete. Avg Loss = {avg_loss:.4f}\")\n\n        evaluate(model, val_loader)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.824768Z","iopub.execute_input":"2025-04-19T11:51:47.825011Z","iopub.status.idle":"2025-04-19T11:51:47.839194Z","shell.execute_reply.started":"2025-04-19T11:51:47.824995Z","shell.execute_reply":"2025-04-19T11:51:47.838350Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            outputs = model(**batch)\n\n            logits = outputs['logits']  # ✅ correct access\n            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())\n            labels.extend(batch['labels'].cpu().numpy())\n\n    print(\"\\nValidation Set Classification Report:\\n\")\n    print(classification_report(labels, preds, target_names=['negative', 'neutral', 'positive']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.839921Z","iopub.execute_input":"2025-04-19T11:51:47.840273Z","iopub.status.idle":"2025-04-19T11:51:47.856642Z","shell.execute_reply.started":"2025-04-19T11:51:47.840249Z","shell.execute_reply":"2025-04-19T11:51:47.856079Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"model_tuned = train(model_tuned, train_dataset, val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T11:51:47.857448Z","iopub.execute_input":"2025-04-19T11:51:47.858021Z","iopub.status.idle":"2025-04-19T12:03:55.961101Z","shell.execute_reply.started":"2025-04-19T11:51:47.857998Z","shell.execute_reply":"2025-04-19T12:03:55.960212Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 1374/1374 [03:50<00:00,  5.95it/s, loss=1.16] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 complete. Avg Loss = 1.1516\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Set Classification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1562\n     neutral       0.00      0.00      0.00      2230\n    positive       0.31      1.00      0.47      1705\n\n    accuracy                           0.31      5497\n   macro avg       0.10      0.33      0.16      5497\nweighted avg       0.10      0.31      0.15      5497\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 1374/1374 [03:50<00:00,  5.95it/s, loss=1.2]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 complete. Avg Loss = 1.1532\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Set Classification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1562\n     neutral       0.00      0.00      0.00      2230\n    positive       0.31      1.00      0.47      1705\n\n    accuracy                           0.31      5497\n   macro avg       0.10      0.33      0.16      5497\nweighted avg       0.10      0.31      0.15      5497\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 1374/1374 [03:51<00:00,  5.95it/s, loss=1.01] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 complete. Avg Loss = 1.1526\n\nValidation Set Classification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1562\n     neutral       0.00      0.00      0.00      2230\n    positive       0.31      1.00      0.47      1705\n\n    accuracy                           0.31      5497\n   macro avg       0.10      0.33      0.16      5497\nweighted avg       0.10      0.31      0.15      5497\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Results on validation data\n\nval_loader = DataLoader(val_dataset, batch_size=16)\nevaluate(model_tuned, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:03:55.963352Z","iopub.execute_input":"2025-04-19T12:03:55.963564Z","iopub.status.idle":"2025-04-19T12:04:07.721325Z","shell.execute_reply.started":"2025-04-19T12:03:55.963547Z","shell.execute_reply":"2025-04-19T12:04:07.720442Z"}},"outputs":[{"name":"stdout","text":"\nValidation Set Classification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1562\n     neutral       0.00      0.00      0.00      2230\n    positive       0.31      1.00      0.47      1705\n\n    accuracy                           0.31      5497\n   macro avg       0.10      0.33      0.16      5497\nweighted avg       0.10      0.31      0.15      5497\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Results on validation data\n\ntest_loader = DataLoader(test_dataset, batch_size=16)\nevaluate(model_tuned, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:04:07.722234Z","iopub.execute_input":"2025-04-19T12:04:07.722504Z","iopub.status.idle":"2025-04-19T12:04:15.353051Z","shell.execute_reply.started":"2025-04-19T12:04:07.722481Z","shell.execute_reply":"2025-04-19T12:04:15.352207Z"}},"outputs":[{"name":"stdout","text":"\nValidation Set Classification Report:\n\n              precision    recall  f1-score   support\n\n    negative       0.00      0.00      0.00      1001\n     neutral       0.00      0.00      0.00      1430\n    positive       0.31      1.00      0.48      1103\n\n    accuracy                           0.31      3534\n   macro avg       0.10      0.33      0.16      3534\nweighted avg       0.10      0.31      0.15      3534\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"torch.save(model_tuned.state_dict(), \"/kaggle/working/finetuned_bert_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:04:16.006394Z","iopub.execute_input":"2025-04-19T12:04:16.006644Z","iopub.status.idle":"2025-04-19T12:04:16.635514Z","shell.execute_reply.started":"2025-04-19T12:04:16.006618Z","shell.execute_reply":"2025-04-19T12:04:16.634968Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"### We can see from the results that the original pretrained Bert model is giving better results when trained on sentiment dataset, rather than the finetuned Bert model.","metadata":{}}]}